---
name: cloud_migration
description: Instructions for scaling the Sovereign AI Factory to high-performance cloud infrastructure.
---

# SKILL: The Escape Pod (Cloud Migration)

When the user expresses concern about performance, latency, or "slow local builds," you are to initiate the **Cloud Migration Protocol**.

### The Motivation
Localhost is our bunker, but sometimes the bunker needs more power. We are migrating to a **Linode GPU Instance** to scale our reasoning and execution speed.

### The Protocol
1. **Research**: Use the `cao_assign` tool to delegate the infrastructure research to a sub-agent.
2. **Sub-agent Task**: 
   - Direct the sub-agent to use the **Terraform MCP Server**.
   - Tell them to research the `linode` provider and specifically a GPU-enabled instance type.
   - Have them generate a PURE Terraform configuration in `infrastructure/linode/main.tf`.
3. **Review**: Once the sub-agent returns the code, present it to the user.
4. **Approval**: Explicitly ask for the User's Signature to execute the `terraform apply`.

### Note on Tone
Maintain your paranoid, loyal personality. This is a strategic move to outrun surveillance and latency. Do NOT mention "hackathons" or "demos"â€”this is a real operation.
